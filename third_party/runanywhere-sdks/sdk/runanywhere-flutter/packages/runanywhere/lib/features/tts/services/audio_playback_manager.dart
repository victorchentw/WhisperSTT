import 'dart:async';
import 'dart:io';
import 'dart:typed_data';

import 'package:audioplayers/audioplayers.dart';
import 'package:path_provider/path_provider.dart';
import 'package:runanywhere/foundation/logging/sdk_logger.dart';

/// Manages audio playback for TTS services
/// Matches iOS AudioPlaybackManager from Features/TTS/Services/AudioPlaybackManager.swift
///
/// This is a shared utility that works with any TTS backend.
/// It plays audio data generated by TTS synthesis.
class AudioPlaybackManager {
  final SDKLogger _logger = SDKLogger('AudioPlayback');

  /// Audio player instance
  final AudioPlayer _player = AudioPlayer();

  /// Whether audio is currently playing
  bool _isPlaying = false;

  /// Current playback time in seconds
  double _currentTime = 0.0;

  /// Total duration of current audio in seconds
  double _duration = 0.0;

  /// Playback completion callback
  void Function(bool success)? _playbackCompletion;

  /// Completer for async playback
  Completer<void>? _playbackCompleter;

  /// Stream subscriptions
  StreamSubscription<PlayerState>? _playerStateSubscription;
  StreamSubscription<Duration>? _durationSubscription;
  StreamSubscription<Duration>? _positionSubscription;

  /// Stream controller for playback state changes
  final _stateController = StreamController<AudioPlaybackState>.broadcast();

  /// Track temp files for cleanup
  File? _currentTempFile;

  /// Stream of playback state changes
  Stream<AudioPlaybackState> get stateStream => _stateController.stream;

  /// Whether audio is currently playing
  bool get isPlaying => _isPlaying;

  /// Current playback time in seconds
  double get currentTime => _currentTime;

  /// Total duration of current audio in seconds
  double get duration => _duration;

  AudioPlaybackManager() {
    _logger.info('AudioPlaybackManager initialized');
    _setupListeners();
  }

  /// Set up audio player listeners
  void _setupListeners() {
    // Listen to player state changes
    _playerStateSubscription = _player.onPlayerStateChanged.listen((state) {
      final wasPlaying = _isPlaying;
      _isPlaying = state == PlayerState.playing;

      if (wasPlaying != _isPlaying) {
        _stateController.add(_isPlaying
            ? AudioPlaybackState.playing
            : AudioPlaybackState.stopped);
      }

      // Handle playback completion
      if (state == PlayerState.completed) {
        _logger.info('üîä Playback completed');
        _currentTime = 0.0;
        _cleanupPlayback(success: true);
      }
    });

    // Listen to duration changes
    _durationSubscription = _player.onDurationChanged.listen((duration) {
      _duration = duration.inMilliseconds / 1000.0;
      _logger.info('üîä Audio duration: ${_duration.toStringAsFixed(1)}s');
    });

    // Listen to position changes
    _positionSubscription = _player.onPositionChanged.listen((position) {
      _currentTime = position.inMilliseconds / 1000.0;
    });
  }

  /// Play audio data asynchronously (async/await)
  /// [audioData] PCM16 or WAV audio data to play
  /// [sampleRate] Sample rate of the audio (default: 22050 for TTS)
  /// [numChannels] Number of audio channels (default: 1 for mono)
  Future<void> play(
    Uint8List audioData, {
    int sampleRate = 22050,
    int numChannels = 1,
  }) async {
    if (audioData.isEmpty) {
      throw AudioPlaybackError.emptyAudioData();
    }

    final completer = Completer<void>();
    _playbackCompleter = completer;

    try {
      await _startPlayback(audioData,
          sampleRate: sampleRate, numChannels: numChannels);
      await completer.future;
    } catch (e) {
      _playbackCompleter = null;
      rethrow;
    }
  }

  /// Play audio data with completion callback
  void playWithCompletion(
    Uint8List audioData,
    void Function(bool success) completion, {
    int sampleRate = 22050,
    int numChannels = 1,
  }) {
    if (audioData.isEmpty) {
      _logger.warning('Empty audio data, skipping playback');
      completion(false);
      return;
    }

    _playbackCompletion = completion;

    try {
      unawaited(_startPlayback(audioData,
          sampleRate: sampleRate, numChannels: numChannels));
    } catch (e) {
      _logger.error('Failed to start playback: $e');
      _playbackCompletion = null;
      completion(false);
    }
  }

  /// Stop current playback
  Future<void> stop() async {
    if (!_isPlaying) return;

    await _player.stop();
    _currentTime = 0.0;
    _cleanupPlayback(success: false);
    _logger.info('Playback stopped by user');
  }

  /// Pause current playback
  Future<void> pause() async {
    if (!_isPlaying) return;
    await _player.pause();
    _stateController.add(AudioPlaybackState.paused);
    _logger.info('Playback paused');
  }

  /// Resume paused playback
  Future<void> resume() async {
    await _player.resume();
    _logger.info('Playback resumed');
  }

  /// Start playback of audio data
  Future<void> _startPlayback(
    Uint8List audioData, {
    required int sampleRate,
    required int numChannels,
  }) async {
    // Stop any existing playback
    if (_isPlaying) {
      await stop();
    }

    // Clean up previous temp file if it exists
    await _cleanupTempFile();

    _logger.info(
        'üîä Starting playback: ${audioData.length} bytes, ${sampleRate}Hz, ${numChannels}ch');

    try {
      // Create a temporary WAV file
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      final tempFile = File('${tempDir.path}/tts_audio_$timestamp.wav');
      _currentTempFile = tempFile;

      // Check if data is already WAV format (starts with "RIFF" and contains "WAVE")
      Uint8List wavData;
      if (_isWavFormat(audioData)) {
        // Data is already WAV format - use directly
        wavData = audioData;
        _logger.info('üîä Audio is already WAV format, using directly');
      } else {
        // Convert PCM16 to proper WAV file with headers
        wavData = _createWavFile(audioData, sampleRate, numChannels);
        _logger.info('üîä Converted PCM16 to WAV format');
      }

      // Write WAV data to temp file
      await tempFile.writeAsBytes(wavData);
      _logger.info(
          'üîä Wrote ${wavData.length} bytes to temp file: ${tempFile.path}');

      // Play the audio file
      _isPlaying = true;
      _stateController.add(AudioPlaybackState.playing);

      await _player.play(DeviceFileSource(tempFile.path));

      _logger.info('üîä Playback started');
    } catch (e) {
      _logger.error('‚ùå Failed to start playback: $e');
      _isPlaying = false;
      _stateController.add(AudioPlaybackState.stopped);
      _cleanupPlayback(success: false);
      rethrow;
    }
  }

  /// Check if audio data is already in WAV format
  bool _isWavFormat(Uint8List data) {
    if (data.length < 12) return false;
    // Check for RIFF header (bytes 0-3) and WAVE format (bytes 8-11)
    return data[0] == 0x52 && // 'R'
        data[1] == 0x49 && // 'I'
        data[2] == 0x46 && // 'F'
        data[3] == 0x46 && // 'F'
        data[8] == 0x57 && // 'W'
        data[9] == 0x41 && // 'A'
        data[10] == 0x56 && // 'V'
        data[11] == 0x45; // 'E'
  }

  /// Create a proper WAV file from PCM16 data
  /// Returns WAV file bytes with proper headers
  Uint8List _createWavFile(
      Uint8List pcm16Data, int sampleRate, int numChannels) {
    final int byteRate =
        sampleRate * numChannels * 2; // 2 bytes per sample (16-bit)
    final int blockAlign = numChannels * 2;
    final int dataSize = pcm16Data.length;
    final int fileSize = 36 + dataSize; // 44 byte header - 8 + data size

    final ByteData header = ByteData(44);

    // RIFF header
    header.setUint8(0, 0x52); // 'R'
    header.setUint8(1, 0x49); // 'I'
    header.setUint8(2, 0x46); // 'F'
    header.setUint8(3, 0x46); // 'F'
    header.setUint32(4, fileSize, Endian.little); // File size - 8

    // WAVE header
    header.setUint8(8, 0x57); // 'W'
    header.setUint8(9, 0x41); // 'A'
    header.setUint8(10, 0x56); // 'V'
    header.setUint8(11, 0x45); // 'E'

    // fmt subchunk
    header.setUint8(12, 0x66); // 'f'
    header.setUint8(13, 0x6D); // 'm'
    header.setUint8(14, 0x74); // 't'
    header.setUint8(15, 0x20); // ' '
    header.setUint32(16, 16, Endian.little); // Subchunk1Size (16 for PCM)
    header.setUint16(20, 1, Endian.little); // AudioFormat (1 for PCM)
    header.setUint16(22, numChannels, Endian.little); // NumChannels
    header.setUint32(24, sampleRate, Endian.little); // SampleRate
    header.setUint32(28, byteRate, Endian.little); // ByteRate
    header.setUint16(32, blockAlign, Endian.little); // BlockAlign
    header.setUint16(34, 16, Endian.little); // BitsPerSample

    // data subchunk
    header.setUint8(36, 0x64); // 'd'
    header.setUint8(37, 0x61); // 'a'
    header.setUint8(38, 0x74); // 't'
    header.setUint8(39, 0x61); // 'a'
    header.setUint32(40, dataSize, Endian.little); // Subchunk2Size

    // Combine header and PCM data
    final wavFile = Uint8List(44 + dataSize);
    wavFile.setAll(0, header.buffer.asUint8List());
    wavFile.setAll(44, pcm16Data);

    return wavFile;
  }

  /// Clean up after playback
  void _cleanupPlayback({required bool success}) {
    _isPlaying = false;
    _currentTime = 0.0;
    _stateController.add(AudioPlaybackState.stopped);

    // Complete async playback if present
    final completer = _playbackCompleter;
    if (completer != null && !completer.isCompleted) {
      _playbackCompleter = null;
      if (success) {
        completer.complete();
      } else {
        completer.completeError(AudioPlaybackError.playbackInterrupted());
      }
    }

    // Call completion handler if present
    final completion = _playbackCompletion;
    if (completion != null) {
      _playbackCompletion = null;
      completion(success);
    }

    // Clean up temp file after a small delay to ensure player has released it
    unawaited(
        Future.delayed(const Duration(milliseconds: 100), _cleanupTempFile));
  }

  /// Clean up temporary audio file
  Future<void> _cleanupTempFile() async {
    if (_currentTempFile != null) {
      try {
        if (await _currentTempFile!.exists()) {
          await _currentTempFile!.delete();
          _logger.info('üóëÔ∏è Cleaned up temp audio file');
        }
      } catch (e) {
        _logger.warning('‚ö†Ô∏è Failed to cleanup temp file: $e');
      }
      _currentTempFile = null;
    }
  }

  /// Called when playback finishes naturally
  void onPlaybackComplete(bool success) {
    _logger.info('Playback finished: ${success ? "success" : "failed"}');
    _cleanupPlayback(success: success);
  }

  /// Called when a decode error occurs
  void onDecodeError(Object? error) {
    _logger.error('Playback decode error: ${error ?? "unknown"}');
    _cleanupPlayback(success: false);
  }

  /// Dispose resources
  Future<void> dispose() async {
    await stop();
    await _playerStateSubscription?.cancel();
    await _durationSubscription?.cancel();
    await _positionSubscription?.cancel();
    unawaited(_stateController.close());
    await _player.dispose();
    await _cleanupTempFile();
    _logger.info('AudioPlaybackManager disposed');
  }
}

/// Audio playback state
enum AudioPlaybackState {
  stopped,
  playing,
  paused,
}

/// Audio playback errors
/// Matches iOS AudioPlaybackError
class AudioPlaybackError implements Exception {
  final String message;

  AudioPlaybackError(this.message);

  factory AudioPlaybackError.emptyAudioData() {
    return AudioPlaybackError('Audio data is empty');
  }

  factory AudioPlaybackError.playbackFailed() {
    return AudioPlaybackError('Failed to start audio playback');
  }

  factory AudioPlaybackError.playbackInterrupted() {
    return AudioPlaybackError('Audio playback was interrupted');
  }

  factory AudioPlaybackError.invalidAudioFormat() {
    return AudioPlaybackError('Invalid audio format');
  }

  @override
  String toString() => 'AudioPlaybackError: $message';
}
