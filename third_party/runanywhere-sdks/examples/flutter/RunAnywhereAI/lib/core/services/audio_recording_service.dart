import 'dart:async';
import 'dart:io';
import 'dart:typed_data';

import 'package:flutter/foundation.dart';
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';

/// Audio Recording Service
///
/// Handles audio recording for Speech-to-Text functionality.
/// Uses the `record` package for cross-platform audio capture.
class AudioRecordingService {
  static final AudioRecordingService instance =
      AudioRecordingService._internal();

  AudioRecordingService._internal();

  final AudioRecorder _recorder = AudioRecorder();

  StreamController<double>? _audioLevelController;
  Timer? _audioLevelTimer;

  bool _isRecording = false;
  String? _currentRecordingPath;

  /// Whether the service is currently recording
  bool get isRecording => _isRecording;

  /// Stream of audio levels (0.0 to 1.0) during recording
  Stream<double>? get audioLevelStream => _audioLevelController?.stream;

  /// Check if microphone permission is granted
  Future<bool> hasPermission() {
    return _recorder.hasPermission();
  }

  /// Start recording audio
  ///
  /// Returns the path to the temporary recording file
  Future<String?> startRecording({
    int sampleRate = 16000,
    int numChannels = 1,
    bool enableAudioLevels = true,
  }) async {
    if (_isRecording) {
      debugPrint('‚ö†Ô∏è Already recording, stopping previous recording first');
      await stopRecording();
    }

    // Check permissions
    final hasPermission = await _recorder.hasPermission();
    if (!hasPermission) {
      debugPrint('‚ùå Microphone permission not granted');
      return null;
    }

    try {
      // Create temp directory for recording
      final tempDir = await getTemporaryDirectory();
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      _currentRecordingPath = '${tempDir.path}/recording_$timestamp.wav';

      // Configure recording
      final config = RecordConfig(
        encoder: AudioEncoder.wav,
        sampleRate: sampleRate,
        numChannels: numChannels,
        bitRate: 128000,
      );

      // Start recording
      await _recorder.start(
        config,
        path: _currentRecordingPath!,
      );

      _isRecording = true;
      debugPrint('üéôÔ∏è Recording started: $_currentRecordingPath');

      // Start audio level monitoring if enabled
      if (enableAudioLevels) {
        _startAudioLevelMonitoring();
      }

      return _currentRecordingPath;
    } catch (e) {
      debugPrint('‚ùå Failed to start recording: $e');
      _isRecording = false;
      _currentRecordingPath = null;
      return null;
    }
  }

  /// Stop recording and return the audio data
  ///
  /// Returns a tuple of (audioData, filePath) or (null, null) if failed
  Future<(Uint8List?, String?)> stopRecording() async {
    if (!_isRecording) {
      debugPrint('‚ö†Ô∏è No active recording to stop');
      return (null, null);
    }

    try {
      // Stop audio level monitoring
      _stopAudioLevelMonitoring();

      // Stop recording
      final path = await _recorder.stop();
      _isRecording = false;

      if (path == null) {
        debugPrint('‚ùå Recording path is null');
        _currentRecordingPath = null;
        return (null, null);
      }

      debugPrint('‚úÖ Recording stopped: $path');

      // Read the recorded audio file
      final file = File(path);
      if (!await file.exists()) {
        debugPrint('‚ùå Recording file does not exist: $path');
        _currentRecordingPath = null;
        return (null, null);
      }

      final audioData = await file.readAsBytes();
      debugPrint('üìä Audio data size: ${audioData.length} bytes');

      final recordingPath = _currentRecordingPath;
      _currentRecordingPath = null;

      // Clean up the temp file after reading
      try {
        await file.delete();
        debugPrint('üóëÔ∏è Cleaned up temp recording file');
      } catch (e) {
        debugPrint('‚ö†Ô∏è Failed to cleanup temp recording file: $e');
      }

      return (audioData, recordingPath);
    } catch (e) {
      debugPrint('‚ùå Failed to stop recording: $e');
      _isRecording = false;
      _currentRecordingPath = null;
      return (null, null);
    }
  }

  /// Cancel current recording without returning data
  Future<void> cancelRecording() async {
    if (!_isRecording) {
      return;
    }

    try {
      _stopAudioLevelMonitoring();
      await _recorder.stop();

      // Delete the temp file if it exists
      if (_currentRecordingPath != null) {
        final file = File(_currentRecordingPath!);
        if (await file.exists()) {
          await file.delete();
        }
      }

      _isRecording = false;
      _currentRecordingPath = null;
      debugPrint('üóëÔ∏è Recording cancelled');
    } catch (e) {
      debugPrint('‚ùå Failed to cancel recording: $e');
      _isRecording = false;
      _currentRecordingPath = null;
    }
  }

  /// Start monitoring audio levels during recording
  void _startAudioLevelMonitoring() {
    _audioLevelController = StreamController<double>.broadcast();

    // Poll for audio amplitude
    _audioLevelTimer =
        Timer.periodic(const Duration(milliseconds: 100), (timer) async {
      if (!_isRecording) {
        timer.cancel();
        return;
      }

      try {
        final amplitude = await _recorder.getAmplitude();
        if (amplitude.current != double.negativeInfinity) {
          // Convert dB to normalized level (0.0 to 1.0)
          // Typical range is -60 dB (quiet) to 0 dB (loud)
          final normalizedLevel =
              ((amplitude.current + 60) / 60).clamp(0.0, 1.0);
          _audioLevelController?.add(normalizedLevel);
        }
      } catch (e) {
        // Ignore errors in amplitude reading
      }
    });
  }

  /// Stop monitoring audio levels
  void _stopAudioLevelMonitoring() {
    _audioLevelTimer?.cancel();
    _audioLevelTimer = null;
    final controller = _audioLevelController;
    if (controller != null) {
      unawaited(controller.close());
    }
    _audioLevelController = null;
  }

  /// Dispose of resources
  Future<void> dispose() async {
    _stopAudioLevelMonitoring();
    if (_isRecording) {
      await cancelRecording();
    }
    await _recorder.dispose();
  }
}
