# RunAnywhere AI - Flutter Example

<p align="center">
  <img src="../../../examples/logo.svg" alt="RunAnywhere Logo" width="120"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Platform-iOS%2013.0%2B%20%7C%20Android%207.0%2B-02569B?style=flat-square&logo=flutter&logoColor=white" alt="iOS 13.0+ | Android 7.0+" />
  <img src="https://img.shields.io/badge/Flutter-3.10%2B-02569B?style=flat-square&logo=flutter&logoColor=white" alt="Flutter 3.10+" />
  <img src="https://img.shields.io/badge/Dart-3.0%2B-0175C2?style=flat-square&logo=dart&logoColor=white" alt="Dart 3.0+" />
  <img src="https://img.shields.io/badge/License-Apache%202.0-blue?style=flat-square" alt="License" />
</p>

**A production-ready reference app demonstrating the [RunAnywhere Flutter SDK](../../../sdk/runanywhere-flutter/) capabilities for on-device AI.** This app showcases how to build privacy-first, offline-capable AI features with LLM chat, speech-to-text, text-to-speech, and a complete voice assistant pipelineâ€”all running locally on your device.

---

## ğŸš€ Running This App (Local Development)

> **Important:** This sample app consumes the [RunAnywhere Flutter SDK](../../../sdk/runanywhere-flutter/) as local path dependencies. Before opening this project, you must first build the SDK's native libraries.

### First-Time Setup

```bash
# 1. Navigate to the Flutter SDK directory
cd runanywhere-sdks/sdk/runanywhere-flutter

# 2. Run the setup script (~10-20 minutes on first run)
#    This builds the native C++ frameworks/libraries and enables local mode
./scripts/build-flutter.sh --setup

# 3. Navigate to this sample app
cd ../../examples/flutter/RunAnywhereAI

# 4. Install dependencies
flutter pub get

# 5. For iOS: Install pods
cd ios && pod install && cd ..

# 6. Run the app
flutter run

# Or open in Android Studio / VS Code and run from there
```

### How It Works

This sample app's `pubspec.yaml` uses path dependencies to reference the local Flutter SDK packages:

```
This Sample App â†’ Local Flutter SDK packages (sdk/runanywhere-flutter/packages/)
                          â†“
              Local XCFrameworks/JNI libs (in each package's ios/Frameworks/ and android/jniLibs/)
                          â†‘
           Built by: ./scripts/build-flutter.sh --setup
```

The `build-flutter.sh --setup` script:
1. Downloads dependencies (ONNX Runtime, Sherpa-ONNX)
2. Builds the native C++ libraries from `runanywhere-commons`
3. Copies XCFrameworks to `packages/*/ios/Frameworks/`
4. Copies JNI `.so` files to `packages/*/android/src/main/jniLibs/`
5. Creates `.testlocal` marker files (enables local library consumption)

### After Modifying the SDK

- **Dart SDK code changes**: Run `flutter run` again (hot reload works for most changes)
- **C++ code changes** (in `runanywhere-commons`):
  ```bash
  cd sdk/runanywhere-flutter
  ./scripts/build-flutter.sh --local --rebuild-commons
  ```

---

## See It In Action

<p align="center">
  <a href="https://apps.apple.com/us/app/runanywhere/id6756506307">
    <img src="https://img.shields.io/badge/App_Store-Download-0D96F6?style=for-the-badge&logo=apple&logoColor=white" alt="Download on App Store" />
  </a>
  <a href="https://play.google.com/store/apps/details?id=com.runanywhere.runanywhereai">
    <img src="https://img.shields.io/badge/Google_Play-Download-3DDC84?style=for-the-badge&logo=android&logoColor=white" alt="Get it on Google Play" />
  </a>
</p>

Try the native iOS and Android apps to experience on-device AI capabilities immediately. The Flutter sample app demonstrates the same features using the cross-platform Flutter SDK.

---

## Screenshots

<p align="center">
  <img src="../../../docs/screenshots/main-screenshot.jpg" alt="RunAnywhere AI Chat Interface" width="220"/>
</p>

---

## Features

This sample app demonstrates the full power of the RunAnywhere Flutter SDK:

| Feature | Description | SDK Integration |
|---------|-------------|-----------------|
| **AI Chat** | Interactive LLM conversations with streaming responses | `RunAnywhere.generateStream()` |
| **Thinking Mode** | Support for models with `<think>...</think>` reasoning | Thinking tag parsing |
| **Real-time Analytics** | Token speed, generation time, inference metrics | `MessageAnalytics` |
| **Speech-to-Text** | Voice transcription with batch & live modes | `RunAnywhere.transcribe()` |
| **Text-to-Speech** | Neural voice synthesis with Piper TTS | `RunAnywhere.synthesize()` |
| **Voice Assistant** | Full STT to LLM to TTS pipeline with auto-detection | `VoiceSession` API |
| **Model Management** | Download, load, and manage multiple AI models | `ModelManager` |
| **Storage Management** | View storage usage and delete models | `RunAnywhere.getStorageInfo()` |
| **Offline Support** | All features work without internet | On-device inference |

---

## Architecture

The app follows Flutter best practices with a clean architecture pattern:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Flutter/Material UI                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Chat    â”‚ â”‚   STT    â”‚ â”‚   TTS    â”‚ â”‚  Voice   â”‚ â”‚  Settings  â”‚ â”‚
â”‚  â”‚Interface â”‚ â”‚  View    â”‚ â”‚  View    â”‚ â”‚Assistant â”‚ â”‚   View     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       â–¼            â–¼            â–¼            â–¼             â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   Provider State Management                   â”‚   â”‚
â”‚  â”‚                   (ModelManager, Services)                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚                    RunAnywhere Flutter SDK                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Core API (generate, transcribe, synthesize)                  â”‚   â”‚
â”‚  â”‚  Model Management (download, load, unload, delete)            â”‚   â”‚
â”‚  â”‚  Voice Session (STT â†’ LLM â†’ TTS pipeline)                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â”‚                                      â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚           â–¼                                      â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   LlamaCpp      â”‚                  â”‚   ONNX Runtime  â”‚          â”‚
â”‚  â”‚   (LLM/GGUF)    â”‚                  â”‚   (STT/TTS)     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Architecture Decisions

- **Provider Pattern** â€” `ChangeNotifier` + `Provider` for state management
- **Feature-First Structure** â€” Each feature is self-contained with its own views and logic
- **Shared Core Services** â€” `ModelManager`, `AudioRecordingService`, `AudioPlayerService`
- **Design System** â€” Consistent `AppColors`, `AppTypography`, `AppSpacing` tokens
- **SDK Integration** â€” Direct SDK calls with async/await and Stream support

---

## Project Structure

```
RunAnywhereAI/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ main.dart                      # App entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ runanywhere_ai_app.dart    # SDK initialization, model registration
â”‚   â”‚   â””â”€â”€ content_view.dart          # Main tab navigation (5 tabs)
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ design_system/
â”‚   â”‚   â”‚   â”œâ”€â”€ app_colors.dart        # Color palette with dark mode support
â”‚   â”‚   â”‚   â”œâ”€â”€ app_spacing.dart       # Spacing constants
â”‚   â”‚   â”‚   â””â”€â”€ typography.dart        # Text styles
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ app_types.dart         # Shared type definitions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ model_manager.dart     # SDK model management wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ audio_recording_service.dart  # Microphone capture
â”‚   â”‚   â”‚   â”œâ”€â”€ audio_player_service.dart     # TTS playback
â”‚   â”‚   â”‚   â”œâ”€â”€ permission_service.dart       # Permission handling
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation_store.dart       # Chat history persistence
â”‚   â”‚   â”‚   â””â”€â”€ device_info_service.dart      # Device capabilities
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utilities/
â”‚   â”‚       â”œâ”€â”€ constants.dart         # Preference keys, defaults
â”‚   â”‚       â””â”€â”€ keychain_helper.dart   # Secure storage wrapper
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”‚   â””â”€â”€ chat_interface_view.dart   # LLM chat with streaming
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ voice/
â”‚   â”‚   â”‚   â”œâ”€â”€ speech_to_text_view.dart   # Batch & live STT
â”‚   â”‚   â”‚   â”œâ”€â”€ text_to_speech_view.dart   # TTS synthesis & playback
â”‚   â”‚   â”‚   â””â”€â”€ voice_assistant_view.dart  # Full STTâ†’LLMâ†’TTS pipeline
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ models_view.dart           # Model browser
â”‚   â”‚   â”‚   â”œâ”€â”€ model_selection_sheet.dart # Model picker bottom sheet
â”‚   â”‚   â”‚   â”œâ”€â”€ model_list_view_model.dart # Model list logic
â”‚   â”‚   â”‚   â”œâ”€â”€ model_components.dart      # Reusable model UI widgets
â”‚   â”‚   â”‚   â”œâ”€â”€ model_status_components.dart # Status badges, indicators
â”‚   â”‚   â”‚   â”œâ”€â”€ model_types.dart           # Framework enums, model info
â”‚   â”‚   â”‚   â””â”€â”€ add_model_from_url_view.dart # Import custom models
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ settings/
â”‚   â”‚       â””â”€â”€ combined_settings_view.dart # Storage & logging config
â”‚   â”‚
â”‚   â””â”€â”€ helpers/
â”‚       â””â”€â”€ adaptive_layout.dart       # Responsive layout utilities
â”‚
â”œâ”€â”€ pubspec.yaml                       # Dependencies, SDK references
â”œâ”€â”€ android/                           # Android platform config
â”œâ”€â”€ ios/                               # iOS platform config
â””â”€â”€ README.md                          # This file
```

---

## Quick Start

### Prerequisites

- **Flutter** 3.10.0 or later ([install guide](https://flutter.dev/docs/get-started/install))
- **Dart** 3.0.0 or later (included with Flutter)
- **iOS** â€” Xcode 14+ (for iOS builds)
- **Android** â€” Android Studio + SDK 21+ (for Android builds)
- **~2GB** free storage for AI models
- **Device** â€” Physical device recommended for best performance

### Clone & Build

```bash
# Clone the repository
git clone https://github.com/RunanywhereAI/runanywhere-sdks.git
cd runanywhere-sdks/examples/flutter/RunAnywhereAI

# Install dependencies
flutter pub get

# Run on connected device
flutter run
```

### Run via IDE

1. Open the project in VS Code or Android Studio
2. Wait for Flutter dependencies to resolve
3. Select a physical device (iOS or Android)
4. Press **F5** (VS Code) or **Run** (Android Studio)

### Build Release APK/IPA

```bash
# Android APK
flutter build apk --release

# Android App Bundle
flutter build appbundle --release

# iOS (requires Xcode)
flutter build ios --release
```

---

## SDK Integration Examples

### Initialize the SDK

The SDK is initialized in `runanywhere_ai_app.dart`:

```dart
import 'package:runanywhere/runanywhere.dart';
import 'package:runanywhere_llamacpp/runanywhere_llamacpp.dart';
import 'package:runanywhere_onnx/runanywhere_onnx.dart';

// 1. Initialize SDK in development mode
await RunAnywhere.initialize();

// 2. Register LlamaCpp module for LLM models (GGUF)
await LlamaCpp.register();
LlamaCpp.addModel(
  id: 'smollm2-360m-q8_0',
  name: 'SmolLM2 360M Q8_0',
  url: 'https://huggingface.co/prithivMLmods/SmolLM2-360M-GGUF/resolve/main/SmolLM2-360M.Q8_0.gguf',
  memoryRequirement: 500000000,
);

// 3. Register ONNX module for STT/TTS models
await Onnx.register();
Onnx.addModel(
  id: 'sherpa-onnx-whisper-tiny.en',
  name: 'Sherpa Whisper Tiny (ONNX)',
  url: 'https://github.com/RunanywhereAI/sherpa-onnx/releases/download/runanywhere-models-v1/sherpa-onnx-whisper-tiny.en.tar.gz',
  modality: ModelCategory.speechRecognition,
  memoryRequirement: 75000000,
);
```

### Download & Load a Model

```dart
// Download with progress tracking (via ModelManager)
await ModelManager.shared.downloadModel(modelInfo);

// Load LLM model
await sdk.RunAnywhere.loadLLMModel('smollm2-360m-q8_0');

// Check if model is loaded
final isLoaded = sdk.RunAnywhere.isModelLoaded;
```

### Stream Text Generation

```dart
// Generate with streaming (real-time tokens)
final streamResult = await RunAnywhere.generateStream(prompt, options: options);

await for (final token in streamResult.stream) {
  // Display each token as it arrives
  setState(() {
    _responseText += token;
  });
}

// Or non-streaming
final result = await RunAnywhere.generate(prompt, options: options);
print('Response: ${result.text}');
print('Speed: ${result.tokensPerSecond} tok/s');
```

### Speech-to-Text

```dart
// Load STT model
await RunAnywhere.loadSTTModel('sherpa-onnx-whisper-tiny.en');

// Transcribe audio bytes
final transcription = await RunAnywhere.transcribe(audioBytes);
print('Transcription: $transcription');
```

### Text-to-Speech

```dart
// Load TTS voice
await RunAnywhere.loadTTSVoice('vits-piper-en_US-lessac-medium');

// Synthesize speech with options
final result = await RunAnywhere.synthesize(
  text,
  rate: 1.0,
  pitch: 1.0,
  volume: 1.0,
);

// Play audio (result.samples is Float32List)
await audioPlayer.play(result.samples, result.sampleRate);
```

### Voice Assistant Pipeline (STT to LLM to TTS)

```dart
// Start voice session
final session = await RunAnywhere.startVoiceSession(
  config: VoiceSessionConfig(),
);

// Listen to session events
session.events.listen((event) {
  if (event is VoiceSessionTranscribed) {
    print('User said: ${event.text}');
  } else if (event is VoiceSessionResponded) {
    print('AI response: ${event.text}');
  } else if (event is VoiceSessionSpeaking) {
    // Audio is being played
  }
});

// Stop session
session.stop();
```

---

## Key Screens Explained

### 1. Chat Screen (`chat_interface_view.dart`)

**What it demonstrates:**
- Streaming text generation with real-time token display
- Thinking mode support (`<think>...</think>` tags)
- Message analytics (tokens/sec, generation time)
- Conversation history with Markdown rendering
- Model selection bottom sheet integration

**Key SDK APIs:**
- `RunAnywhere.generateStream()` â€” Streaming generation
- `RunAnywhere.generate()` â€” Non-streaming generation
- `RunAnywhere.currentLLMModel()` â€” Get loaded model info

### 2. Speech-to-Text Screen (`speech_to_text_view.dart`)

**What it demonstrates:**
- Batch mode: Record full audio, then transcribe
- Live mode: Real-time streaming transcription (when supported)
- Audio level visualization
- Mode selection (batch vs. live)

**Key SDK APIs:**
- `RunAnywhere.loadSTTModel()` â€” Load Whisper model
- `RunAnywhere.transcribe()` â€” Batch transcription
- `RunAnywhere.isSTTModelLoaded` â€” Check model status

### 3. Text-to-Speech Screen (`text_to_speech_view.dart`)

**What it demonstrates:**
- Neural voice synthesis with Piper TTS
- Speed and pitch controls with sliders
- Audio playback with progress indicator
- Audio metadata display (duration, sample rate, size)

**Key SDK APIs:**
- `RunAnywhere.loadTTSVoice()` â€” Load TTS model
- `RunAnywhere.synthesize()` â€” Generate speech audio
- `RunAnywhere.isTTSVoiceLoaded` â€” Check voice status

### 4. Voice Assistant Screen (`voice_assistant_view.dart`)

**What it demonstrates:**
- Complete voice AI pipeline (STT to LLM to TTS)
- Model configuration for all 3 components
- Audio level visualization during recording
- Conversation turn management
- Session state machine (connecting, listening, processing, speaking)

**Key SDK APIs:**
- `RunAnywhere.startVoiceSession()` â€” Start voice session
- `RunAnywhere.isVoiceAgentReady` â€” Check all components loaded
- `VoiceSessionEvent` â€” Session event stream

### 5. Settings Screen (`combined_settings_view.dart`)

**What it demonstrates:**
- Storage usage overview (total, available, model storage)
- Downloaded model list with details
- Model deletion with confirmation dialog
- Analytics logging toggle

**Key SDK APIs:**
- `RunAnywhere.getStorageInfo()` â€” Get storage details
- `RunAnywhere.getDownloadedModelsWithInfo()` â€” List models
- `RunAnywhere.deleteStoredModel()` â€” Remove model

---

## Supported Models

### LLM Models (LlamaCpp/GGUF)

| Model | Size | Memory | Description |
|-------|------|--------|-------------|
| SmolLM2 360M Q8_0 | ~400MB | 500MB | Fast, lightweight chat |
| Qwen 2.5 0.5B Q6_K | ~500MB | 600MB | Multilingual, efficient |
| LFM2 350M Q4_K_M | ~200MB | 250MB | LiquidAI, ultra-compact |
| LFM2 350M Q8_0 | ~350MB | 400MB | Higher quality version |
| Llama 2 7B Chat Q4_K_M | ~4GB | 4GB | Powerful, larger model |
| Mistral 7B Instruct Q4_K_M | ~4GB | 4GB | High quality responses |

### STT Models (ONNX/Whisper)

| Model | Size | Description |
|-------|------|-------------|
| Sherpa Whisper Tiny (EN) | ~75MB | Fast English transcription |
| Sherpa Whisper Small (EN) | ~250MB | Higher accuracy |

### TTS Models (ONNX/Piper)

| Model | Size | Description |
|-------|------|-------------|
| Piper US English (Medium) | ~65MB | Natural American voice |
| Piper British English (Medium) | ~65MB | British accent |

---

## Testing

### Run Tests

```bash
# Run all tests
flutter test

# Run with coverage
flutter test --coverage

# Run specific test file
flutter test test/widget_test.dart
```

### Run Lint & Analysis

```bash
# Analyze code quality
flutter analyze

# Format code
dart format lib/ test/

# Fix issues automatically
dart fix --apply
```

---

## Debugging

### Enable Verbose Logging

The app uses `debugPrint()` extensively. Filter logs by:

```bash
# Flutter logs
flutter logs | grep -E "RunAnywhere|SDK"
```

### Common Debug Messages

| Log Prefix | Description |
|------------|-------------|
| `SDK` | SDK initialization |
| `SUCCESS` | Success operations |
| `ERROR` | Error conditions |
| `MODULE` | Module registration |
| `LOADING` | Loading/processing |
| `AUDIO` | Audio operations |
| `RECORDING` | Recording operations |

### Memory Profiling

1. Run app in profile mode: `flutter run --profile`
2. Open DevTools: Press `p` in terminal
3. Navigate to Memory tab
4. Expected: ~300MB-2GB depending on model size

---

## Configuration

### Environment Setup

The SDK automatically detects the environment:

```dart
// Development mode (default)
if (kDebugMode) {
  await RunAnywhere.initialize();
}

// Production mode
else {
  await RunAnywhere.initialize(
    apiKey: 'your-api-key',
    baseURL: 'https://api.runanywhere.ai',
    environment: SDKEnvironment.production,
  );
}
```

### Preference Keys

User preferences are stored via `SharedPreferences`:

| Key | Type | Default | Description |
|-----|------|---------|-------------|
| `useStreaming` | bool | `true` | Enable streaming generation |
| `defaultTemperature` | double | `0.7` | LLM temperature |
| `defaultMaxTokens` | int | `500` | Max tokens per generation |

---

## Known Limitations

- **ARM64 Recommended** â€” Native libraries optimized for arm64 (x86 emulators may be slow)
- **Memory Usage** â€” Large models (7B+) require devices with 6GB+ RAM
- **First Load** â€” Initial model loading takes 1-3 seconds (cached afterward)
- **Live STT** â€” Requires WhisperKit-compatible models (limited in ONNX)
- **Platform Channels** â€” Some SDK features use FFI/platform channels

---

## Contributing

We welcome contributions! See [CONTRIBUTING.md](../../../CONTRIBUTING.md) for guidelines.

### Development Setup

```bash
# Fork and clone
git clone https://github.com/YOUR_USERNAME/runanywhere-sdks.git
cd runanywhere-sdks/examples/flutter/RunAnywhereAI

# Create feature branch
git checkout -b feature/your-feature

# Make changes and test
flutter pub get
flutter analyze
flutter test

# Commit and push
git commit -m "feat: your feature description"
git push origin feature/your-feature

# Open Pull Request
```

---

## License

This project is licensed under the Apache License 2.0 - see [LICENSE](../../../LICENSE) for details.

---

## Support

- **Discord**: [Join our community](https://discord.gg/N359FBbDVd)
- **GitHub Issues**: [Report bugs](https://github.com/RunanywhereAI/runanywhere-sdks/issues)
- **Email**: san@runanywhere.ai
- **Twitter**: [@RunanywhereAI](https://twitter.com/RunanywhereAI)

---

## Related Documentation

- [RunAnywhere Flutter SDK](../../../sdk/runanywhere-flutter/README.md) â€” Full SDK documentation
- [iOS Example App](../../ios/RunAnywhereAI/README.md) â€” iOS counterpart
- [Android Example App](../../android/RunAnywhereAI/README.md) â€” Android counterpart
- [React Native Example](../../react-native/RunAnywhereAI/README.md) â€” React Native option
- [Main README](../../../README.md) â€” Project overview
